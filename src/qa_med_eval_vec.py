import os
import json
import csv
from typing import List, Dict, Set, Tuple

import numpy as np
from sentence_transformers import SentenceTransformer

# å¤ç”¨ answer_vec_drugs é‡Œå†™å¥½çš„å·¥å…·å‡½æ•°
from answer_vec_drugs import (
    load_docs,
    load_vec_index,
    vec_search,
    doc_text,
    extract_drugs_from_text,
)

DOCS_PATH = os.path.join("data", "docs.jsonl")
VEC_EMB_PATH = os.path.join("data", "index_vec_emb.npy")
QUEST_PATH = os.path.join("data", "qa_med_questions.jsonl")
OUT_CSV = os.path.join("runs", "qa_med_eval_vec.csv")

MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
TOP_K = 20  # å‘é‡æ£€ç´¢çš„æ–‡çŒ®æ•°ï¼Œå¯ä»¥ä»¥åè°ƒå‚


def f1_score(p: float, r: float) -> float:
    if p == 0.0 or r == 0.0:
        return 0.0
    return 2 * p * r / (p + r)


def eval_one_question(
    question: str,
    gold_drugs: List[str],
    docs: List[Dict],
    emb: np.ndarray,
    model: SentenceTransformer,
    top_k: int = TOP_K,
) -> Tuple[List[str], int, int, int, int, int, float, float, float]:
    """
    å¯¹å•ä¸ªé—®é¢˜åšï¼š
      - å‘é‡æ£€ç´¢ Top-K
      - æŠŠè¿™ K ç¯‡æ–‡ç« æ‹¼èµ·æ¥æŠ½è¯å
      - å’Œ gold å¯¹æ¯”ï¼Œç®— P/R/F1
    """
    # 1) å‘é‡æ£€ç´¢
    idx, scores = vec_search(question, model, emb, top_k=top_k)

    # 2) æ‹¼æ¥æ–‡æœ¬
    big_chunks = []
    for i in idx:
        doc = docs[int(i)]
        big_chunks.append(doc_text(doc))
    big_text = "\n\n".join(big_chunks)

    # 3) æŠ½è¯å
    pred_drugs = extract_drugs_from_text(big_text)

    # 4) è®¡ç®—æŒ‡æ ‡
    gold_set: Set[str] = set(d.lower() for d in gold_drugs)
    pred_set: Set[str] = set(d.lower() for d in pred_drugs)

    tp_set = gold_set & pred_set
    fp_set = pred_set - gold_set
    fn_set = gold_set - pred_set

    tp = len(tp_set)
    fp = len(fp_set)
    fn = len(fn_set)

    pred_size = len(pred_set)
    gold_size = len(gold_set)

    if pred_size == 0:
        precision = 0.0
    else:
        precision = tp / pred_size

    if gold_size == 0:
        recall = 0.0
    else:
        recall = tp / gold_size

    f1 = f1_score(precision, recall)

    # ä¸ºäº†è¾“å‡ºå¥½çœ‹ï¼Œpred_drugs ç”¨åŸå§‹çš„å¤§å°å†™é¡ºåº
    return pred_drugs, gold_size, pred_size, tp, fp, fn, precision, recall, f1


def load_questions(path: str = QUEST_PATH) -> List[Dict]:
    qs = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            obj = json.loads(line)
            qs.append(obj)
    return qs


def main():
    os.makedirs("runs", exist_ok=True)

    print(f"ğŸ“„ è¯»å–é—®é¢˜æ–‡ä»¶ï¼š{QUEST_PATH}")
    questions = load_questions(QUEST_PATH)
    print(f"âœ… å…±è¯»å– {len(questions)} ä¸ªé—®é¢˜")

    print(f"ğŸ“„ è¯»å–è¯­æ–™ï¼š{DOCS_PATH}")
    docs = load_docs(DOCS_PATH)
    print(f"âœ… æ–‡çŒ®æ¡æ•°ï¼š{len(docs)}")

    print(f"ğŸ“¦ è¯»å–å‘é‡ç´¢å¼•ï¼š{VEC_EMB_PATH}")
    emb = load_vec_index()

    if emb.shape[0] != len(docs):
        raise RuntimeError(
            f"âŒ å‘é‡æ¡æ•° {emb.shape[0]} å’Œ docs æ¡æ•° {len(docs)} ä¸ä¸€è‡´ï¼Œè¯·ç¡®è®¤ç”¨åŒä¸€ä»½ docs.jsonl é‡å»ºå‘é‡ç´¢å¼•ã€‚"
        )

    print(f"ğŸ§  åŠ è½½å‘é‡æ¨¡å‹ï¼š{MODEL_NAME}")
    model = SentenceTransformer(MODEL_NAME)

    rows = []

    # micro ç»Ÿè®¡
    micro_tp = micro_fp = micro_fn = 0

    # macro ç»Ÿè®¡
    macro_p_list = []
    macro_r_list = []
    macro_f1_list = []

    for q in questions:
        qid = q.get("id", "")
        qtext = q.get("question", "")
        gold_drugs = q.get("gold_drugs", [])

        print(f"\n=== è¯„æµ‹é—®é¢˜ {qid} ===")
        print(qtext)

        (
            pred_drugs,
            gold_size,
            pred_size,
            tp,
            fp,
            fn,
            p,
            r,
            f1,
        ) = eval_one_question(qtext, gold_drugs, docs, emb, model, top_k=TOP_K)

        print(
            f"TP={tp} FP={fp} FN={fn}  P={p:.4f} R={r:.4f} F1={f1:.4f}"
        )
        print("é¢„æµ‹è¯ç‰©ï¼š", ";".join(pred_drugs))

        # ç´¯è®¡ micro
        micro_tp += tp
        micro_fp += fp
        micro_fn += fn

        # ç´¯è®¡ macro
        macro_p_list.append(p)
        macro_r_list.append(r)
        macro_f1_list.append(f1)

        rows.append(
            {
                "id": qid,
                "question": qtext,
                "gold_size": gold_size,
                "pred_size": pred_size,
                "tp": tp,
                "fp": fp,
                "fn": fn,
                "precision": f"{p:.4f}",
                "recall": f"{r:.4f}",
                "f1": f"{f1:.4f}",
                "gold_drugs": ";".join(gold_drugs),
                "pred_drugs": ";".join(pred_drugs),
            }
        )

    # è®¡ç®— micro
    if micro_tp + micro_fp == 0:
        micro_p = 0.0
    else:
        micro_p = micro_tp / (micro_tp + micro_fp)

    if micro_tp + micro_fn == 0:
        micro_r = 0.0
    else:
        micro_r = micro_tp / (micro_tp + micro_fn)

    micro_f1 = f1_score(micro_p, micro_r)

    # è®¡ç®— macro
    if macro_p_list:
        macro_p = sum(macro_p_list) / len(macro_p_list)
        macro_r = sum(macro_r_list) / len(macro_r_list)
        macro_f1 = sum(macro_f1_list) / len(macro_f1_list)
    else:
        macro_p = macro_r = macro_f1 = 0.0

    print("=" * 80)
    print(f"âœ… å·²å†™å‡ºè¯„æµ‹ç»“æœåˆ°ï¼š{OUT_CSV}")
    print(
        f"ğŸ”¢ å¾®å¹³å‡ (micro)ï¼šP={micro_p:.3f}  R={micro_r:.3f}  F1={micro_f1:.3f}"
    )
    print(
        f"ğŸ”¢ å®å¹³å‡ (macro)ï¼šP={macro_p:.3f}  R={macro_r:.3f}  F1={macro_f1:.3f}"
    )

    # å†™ CSV
    with open(OUT_CSV, "w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=[
                "id",
                "question",
                "gold_size",
                "pred_size",
                "tp",
                "fp",
                "fn",
                "precision",
                "recall",
                "f1",
                "gold_drugs",
                "pred_drugs",
            ],
        )
        writer.writeheader()
        writer.writerows(rows)


if __name__ == "__main__":
    main()
